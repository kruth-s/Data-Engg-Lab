{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "714d189a-e63d-429d-9d72-6bd16dc2d236",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\skrut\\AppData\\Local\\Temp\\ipykernel_15700\\1278051323.py:28: UserWarning: Parsing dates in %d-%m-%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  sales_df['sale_month'] = pd.to_datetime(sales_df['sale_date'], errors='coerce').dt.to_period('M')\n",
      "C:\\Users\\skrut\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Customer-Level Data:\n",
      "  customer_id  total_purchase_amount  purchase_count  \\\n",
      "0       C_001                  520.5               3   \n",
      "1       C_002                   75.0               1   \n",
      "2       C_003                  270.0               2   \n",
      "3       C_004                   30.0               1   \n",
      "4       C_005                   75.0               1   \n",
      "\n",
      "   average_transaction_value  purchase_frequency  sentiment_score  \n",
      "0                      173.5                   2         3.600000  \n",
      "1                       75.0                   0         4.316667  \n",
      "2                      135.0                   1         2.900000  \n",
      "3                       30.0                   1         2.928571  \n",
      "4                       75.0                   1         3.728571  \n",
      "\n",
      "[INFO] Enriched data saved to 'enriched_customer_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "# VIP Customer Classification with Reverse ETL (Sales + Sentiment Data)\n",
    "# ---------------------------------------------------------------------\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import sqlalchemy\n",
    "import json\n",
    "\n",
    "# ---------------- Step 1: Load CSV & JSON ----------------\n",
    "sales_df = pd.read_csv(\"./raw_data/sale_price.csv\")\n",
    "\n",
    "with open(\"./raw_data/customer_feedback.json\", \"r\") as f:\n",
    "    sentiments_data = json.load(f)\n",
    "\n",
    "sentiments_df = pd.DataFrame(sentiments_data)\n",
    "# ---------------- Step 2: Feature Engineering from Sales ----------------\n",
    "# Convert sale_price to numeric (remove $ sign)\n",
    "sales_df['sale_price'] = sales_df['sale_price'].replace('[\\$,]', '', regex=True).astype(float)\n",
    "\n",
    "# Compute per-customer metrics\n",
    "agg_sales = sales_df.groupby('customer_id').agg(\n",
    "    total_purchase_amount=('sale_price', 'sum'),\n",
    "    purchase_count=('sale_id', 'count'),\n",
    "    average_transaction_value=('sale_price', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "# Purchase frequency: purchases per unique month in dataset\n",
    "sales_df['sale_month'] = pd.to_datetime(sales_df['sale_date'], errors='coerce').dt.to_period('M')\n",
    "freq = sales_df.groupby('customer_id')['sale_month'].nunique().reset_index(name='purchase_frequency')\n",
    "\n",
    "# Merge the frequency into aggregated sales\n",
    "agg_sales = agg_sales.merge(freq, on='customer_id', how='left')\n",
    "\n",
    "# ---------------- Step 3: Merge with Sentiments ----------------\n",
    "# If multiple reviews per customer, average sentiment\n",
    "agg_sentiments = sentiments_df.groupby('customer_id', as_index=False).agg(\n",
    "    sentiment_score=('sentiment_score', 'mean')\n",
    ")\n",
    "\n",
    "combined_df = pd.merge(agg_sales, agg_sentiments, on=\"customer_id\", how=\"left\").fillna(0)\n",
    "\n",
    "print(\"Combined Customer-Level Data:\")\n",
    "print(combined_df.head())\n",
    "\n",
    "# ---------------- Step 4: Preprocess ----------------\n",
    "features = ['total_purchase_amount', 'purchase_frequency', 'average_transaction_value', 'sentiment_score']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "combined_df[features] = scaler.fit_transform(combined_df[features])\n",
    "\n",
    "# ---------------- Step 5: K-Means Clustering ----------------\n",
    "X = combined_df[features]\n",
    "kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
    "combined_df['vip_cluster'] = kmeans.fit_predict(X)\n",
    "\n",
    "# Identify VIP cluster based on highest spending\n",
    "vip_cluster_label = combined_df.groupby('vip_cluster')['total_purchase_amount'].mean().idxmax()\n",
    "combined_df['VIP_Status'] = combined_df['vip_cluster'].apply(lambda x: 'VIP' if x == vip_cluster_label else 'Non-VIP')\n",
    "\n",
    "# ---------------- Step 6: Reverse ETL (Export) ----------------\n",
    "combined_df.to_csv(\"data_warehouse/enriched_customer_data.csv\", index=False)\n",
    "print(\"\\n[INFO] Enriched data saved to 'enriched_customer_data.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6b972b-4286-4a5b-b5dd-5ff3a7f9fd02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
